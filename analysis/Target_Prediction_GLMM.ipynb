{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN40Xsb1hwja4oVTQwwkUFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/o-fugi/FURSPColexification/blob/main/code/Mixed_Effect_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell and then restart the runtime if you want to generate special fancy graphs\n",
        "\n",
        "# !pip install matplotlib --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "URPn63FtU1dZ",
        "outputId": "7447c374-b0c6-4246-cae0-6de2b9f12827"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.37.3-py3-none-any.whl (959 kB)\n",
            "\u001b[K     |████████████████████████████████| 959 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed fonttools-4.37.3 matplotlib-3.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/ColabFiles/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwtytK6h2xdv",
        "outputId": "8335d11f-4dfb-4a06-f645-b1c8b812478c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/ColabFiles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q7rn6PCy2otq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from functools import reduce\n",
        "import random as r\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import gpboost as gpb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "lULCtRrC39LM",
        "outputId": "1b2487a0-a694-4267-aa4f-112dc835f610"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-65.4.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 2.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "numba 0.56.2 requires setuptools<60, but you have setuptools 65.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed setuptools-65.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpboost -U\n",
        "import gpboost as gpb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIl9nYxo4COq",
        "outputId": "6030f69a-66d2-4bd5-8395-48cb40b7c0a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpboost\n",
            "  Downloading gpboost-0.7.9-py3-none-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.21.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gpboost) (0.37.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->gpboost) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->gpboost) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gpboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gpboost) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->gpboost) (1.15.0)\n",
            "Installing collected packages: gpboost\n",
            "Successfully installed gpboost-0.7.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import factor  datasets\n",
        "\n",
        "# https://saifmohammad.com/WebPages/nrc-vad.html\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/ColabFiles/NRC-VAD-Lexicon.txt', sep=\"\\t\", header=None)\n",
        "val_df = val_df.rename(columns={0:'Word', 1:'val', 2:'aro', 3:'dom'})[['Word', 'val', 'aro', 'dom']]\n",
        "\n",
        "conc_df = pd.read_csv('/content/drive/MyDrive/ColabFiles/brysbaert_concreteness.csv')\n",
        "conc_df = conc_df.rename(columns={'Conc.M': 'conc'})[['Word', 'conc']]\n",
        "\n",
        "freq_df = pd.read_csv('/content/drive/MyDrive/ColabFiles/COCA_freqs.csv', encoding='ISO-8859-1') # w1, coca_spok\n",
        "freq_df = freq_df.rename(columns={'w1':'Word', 'coca_spok':'freq'})[['Word', 'freq']]"
      ],
      "metadata": {
        "id": "jhh6QgLl2yte"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import semantic shift dataset\n",
        "\n",
        "sem_shift_df = pd.read_csv('/content/drive/MyDrive/ColabFiles/cleaned_dat_sem_shift.csv')\n",
        "sem_shift_df['meaning1'] = sem_shift_df['meaning1_clean']\n",
        "sem_shift_df['meaning2'] = sem_shift_df['meaning2_clean']\n",
        "sem_shift_df = sem_shift_df[['meaning1', 'meaning2', 'realizations']]\n",
        "\n",
        "sem_shift_df.at[697, 'meaning1'] = 'furuncul'\n",
        "sem_shift_df.at[1521, 'meaning2'] = 'geometrid'"
      ],
      "metadata": {
        "id": "e8iBqeZq3XNv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the dataset all figured out \n",
        "datSemShift = pd.read_csv('/content/drive/MyDrive/ColabFiles/datsemshift.csv')\n",
        "\n",
        "# filter semantic shifts\n",
        "datSemShift = datSemShift[(datSemShift['gendirection'] == '→')]\n",
        "datSemShift = datSemShift[(datSemShift['type'] == ' Semantic evolution') | (datSemShift['type'] == ' Polysemy')]\n",
        "datSemShift = datSemShift[(datSemShift['language1'] == datSemShift['language2'])]\n",
        "datSemShift = datSemShift[(datSemShift['lexeme1'] == datSemShift['lexeme2'])]\n",
        "datSemShift = datSemShift[~datSemShift['meaning1'].str.contains('<')]\n",
        "datSemShift = datSemShift[~datSemShift['meaning2'].str.contains('<')]\n",
        "datSemShift = datSemShift[(datSemShift['status']!='Suspended') & (datSemShift['status']!='Rejected')]\n",
        "datSemShift = datSemShift[['meaning1', 'meaning2', 'language1']]\n",
        "datSemShift = datSemShift.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "0THNVD4FwP5t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dumb_british_spellings = {\"vapour\":\"vapor\", \"honour\":\"honor\", \"organisation\":\"organization\", \"harbour\":\"harbor\", \"odour\":\"odor\", \"centre\":\"center\", \"analyse\":\"analyze\", \"theatre\":\"theater\", \"colour\":\"color\", \"rumour\":\"rumor\", \"behaviour\":\"behavior\", \"armour\":\"armor\", \"grey\":\"gray\", \n",
        "\"mould\":\"mold\", \"neighbour\":\"neighbor\", \"axe\":\"ax\", \"moustache\":\"mustache\", \"plough\":\"plow\", \"mandarine\":\"mandarin\"}\n",
        "words_to_replace = {\"adj\":\"\", \"gipsy\":\"\", \"albumen\":\"\", \"campanula\":\"\", \"boletus edulis\":\"penny bun fungus\", \"ursus\":\"\", \"swearword\":\"swear word\", 'adj.':\"\", \"coleus\":\"\", 'n.':\"\", 'ОК':\"ok\", \"typha\":\"cattail\", \"pacifica\":\"peaceful\", \"mustella\":\"\", \"smail\":\"\", \"one’s\":\"\", \"spurflower\":\"perennial plant\", \"sabre\":\"\",\"equus\":\"\", \"etc.\":\"\", \"ciconia\":\"\",  \"aër\":\"\", \"panthera\":\"panther\", \"еrinaceus\":\"\", \"e.g.\":\"\", \"centaurea\":\"thistle\", \"moschiferus\":\"\", \"apterus\":\"\", \"pyrrhocoris\":\"\", \"smn.\":\"\", \"pritchardia\":\"\", \"100\":\"one hundred\", \"sabrefish\":\"sabre carp\", \"putorius\":\"\", \"adv.\":\"\", \"petromyzontidae\":\"\", \"botaurus\":\"\", \"standart\":\"standard\", \"leccinum\":\"\", \"sg.\":\"\", \"gemini\":\"Gemini\", \"tabanidae\":\"\", \"anagallis\":\"\", \"decorticate\":\"stiff\", \"albugo\":\"\", \"frangula\":\"\", \"sciurus\":\"\", \"scrofa\":\"\", \"relig.\":\"\", \"headstream\":\"head stream\", \"solanum\":\"\", \"anguilla\":\"\", \"anat.\":\"\", \"nectarinia\":\"\", \"ipomoea\":\"\", \"repaire\":\"repair\", \"vaccinium\":\"\", \"smth\":\"\", \"smth.\":\"\", \"bubo\":\"\", \"deflorate\":\"remove flowers\", \"tr.\":\"\", \"traveller\":\"traveler\", \"bubalis\":\"\", \"marmorata\":\"\", \"furuncul\":\"\", \"caballus\":\"\", \"microchiroptera\":\"\", \"urtica\":\"\", \"plumbum\":\"\", \"biol.\":\"\", \"intr.\":\"\", \"bubalus\":\"\", \"columba\":\"\", \"cucurbita\":\"\", \"goldcrest\":\"small bird\", \"melongena\":\"\", \"picea\":\"\", \"arvensis\":\"\", \"moschus\":\"\", \"psidium\":\"\", \"radiointerference\":\"radio interference\", \"owre\":\"\", \"ricinus\":\"\", \"capricorn\":\"goat zodiac sign\", \"mustela\":\"\", \"pandion\":\"\", \"adj.of\":\"\", \"nomadize\":\"become nomadic\", \"smb.\":\"\", \"kneepit\":\"knee pit\", \"num.\":\"\", \"pl.\":\"\", \"extortioner\":\"extortion doer\", \"enculturate\":\"assimilate\", \"asquint\":\"squint\", \"uliginosum\":\"\", \"heteroptera\":\"\", \"ок\":\"ok\", \"abies\":\"fir\", \"stratiotes\":\"\", \"fiddlestick\":\"violin bow\", \"scabrum\":\"\", \"grus\":\"bird\", \"acarina\":\"\", \"guajava\":\"\", \"bitterling\":\"freshwater fish\", \"lycopersicum\":\"\", \"lutra\":\"otter\", \"plectranthus\":\"\", \"macereed\":\"mace reed\", \"24\":\"twenty four\", \"acris\":\"\", \"rotundifolius\":\"common weed\", \"gutturalis\":\"\", \"oxyeleotris\":\"\", \"geometrid\":\"\", \"citrullus\":\"\", \"lepus\":\"\", \"motacilla\":\"\", \"crake\":\"bird\", \"haliaёtus\":\"\", \"glasswort\":\"herb\", \"quinsy\":\"throat abscess\", \"shoulderblade\":\"shoulder blade\", \"spearthrower\":\"spear thrower\", \"ridgepole\":\"ridge pole\", \"pimpleface\":\"pimple face\", \"tumpline\":\"backpack\", \"cushma\":\"clothing\", \"curassow\":\"tropical bird\", \"banisterium\":\"plant\", \"paca\":\"rodent\", \"netbag\":\"net bag\", \"muntjacs\":\"barking deer\"}\n",
        "#Replaces obscure words with recognizable words, replaces parts of speech with nothing, same with science words\n",
        "\n",
        "def clean(s): # Here is the main method where we clean senses\n",
        "  s = str(s)\n",
        "  for i in \",:\":\n",
        "    s = s.replace(i, \" or\")\n",
        "  s = s.replace(\"/\", \" or \")\n",
        "  for i in \"()\\t\\n<>?’\":\n",
        "    s = s.replace(i, \"\")\n",
        "  for i in \"-\":\n",
        "    s = s.replace(i, \" \")\n",
        "  should_be_upper = {}\n",
        "  for w in s.split(\" \"):\n",
        "    if w != \"\" and w[0].isupper():\n",
        "      should_be_upper = {w.lower():w.capitalize()} # Keeps track of which words should be capitalized\n",
        "  s = s.lower() # Converts to lowercase\n",
        "  for i in dumb_british_spellings: # Replaces British spelling with American ones\n",
        "    s = s.replace(i, dumb_british_spellings[i])\n",
        "  for i in words_to_replace: # Replaces all other obscure words \n",
        "    s = s.replace(i, words_to_replace[i])\n",
        "  for i in should_be_upper: # Uppercases words which should be uppercase\n",
        "    s = s.replace(i, should_be_upper[i])\n",
        "  if len(s) > 2 and s[:3] == \" or\": # If the beginning word is or, that means our string was of the form \"[removed word],\" and we should delete the or\n",
        "    s = s[3:]\n",
        "  if \"vs.\" in s: # For cases like \"land (vs. sea)\"\" we want to convert this to \"land\"\n",
        "    ind = s.find(\"vs.\")\n",
        "    s = s[:ind]\n",
        "  s = s.replace(\".\",\"\")\n",
        "  return s\n",
        "\n",
        "df_raw = datSemShift\n",
        "sem_shift_df = df_raw.copy()\n",
        "sem_shift_df['meaning1'] = sem_shift_df[\"meaning1\"].apply(clean)\n",
        "sem_shift_df['meaning2'] = sem_shift_df[\"meaning2\"].apply(clean)"
      ],
      "metadata": {
        "id": "ooWvcVTzwVkV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define how we map a sense to concreteness, valence, frequency values\n",
        "\n",
        "skip_words = {'the', 'and', 'of', 'a', 'in', 'to', 'it', 'is', 'that', 'for', 'with', 'on', 'at', 'this', 'that', 'by', 'or', 'an', 'as', 'if', 'so', 'in'}\n",
        "\n",
        "# take all words in the sense and and average/add values\n",
        "# if conservative, only matches to full phrases separated by \"or\"\n",
        "def senseToValue(s, df, col, average=True, conservative=False):\n",
        "  s = s.lower()\n",
        "  if conservative: \n",
        "    phrases = re.split(' or ', s)\n",
        "  else:\n",
        "    for i in \"(),/\":\n",
        "      s = s.replace(i, \"\")\n",
        "    phrases = re.split(' ', s)\n",
        "  total_val = 0\n",
        "  val_data = 0\n",
        "  for p in phrases:\n",
        "    if p in skip_words:\n",
        "      continue\n",
        "    try:\n",
        "      val = df[df['Word']==p][col].values[0]\n",
        "      if not np.isnan(val):\n",
        "        total_val += val\n",
        "        val_data += 1\n",
        "    except:\n",
        "      pass\n",
        "  if val_data == 0:\n",
        "    total_val = np.nan\n",
        "  else:\n",
        "    if average:\n",
        "      total_val /= val_data\n",
        "  return total_val"
      ],
      "metadata": {
        "id": "n83l-7jX4qiW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get priors for semshift data\n",
        "\n",
        "# dictionary for concreteness and embeddings\n",
        "conc_dic = {} # This will be a dictionary that easily allows us to access the concreteness for all of our senses, saving time. \n",
        "freq_dic = {} \n",
        "val_dic = {}\n",
        "val_rate_dic = {}\n",
        "\n",
        "conservative=True\n",
        "\n",
        "for i in range(len(sem_shift_df)): # Here we loop through each row of our dataframe, and if we can convert a sense s to an embedding then we set vec_dic[s] = embedding\n",
        "  row = sem_shift_df.iloc[i]\n",
        "  x = row[\"meaning1\"]\n",
        "  y = row[\"meaning2\"]\n",
        "\n",
        "  if x not in conc_dic:\n",
        "    x_conc = senseToValue(x, conc_df, 'conc', conservative=conservative)\n",
        "    if not np.isnan(x_conc):\n",
        "      conc_dic[x] = x_conc\n",
        "\n",
        "  if y not in conc_dic:\n",
        "    y_conc = senseToValue(y, conc_df, 'conc', conservative=conservative)\n",
        "    if not np.isnan(y_conc):\n",
        "      conc_dic[y] = y_conc\n",
        "\n",
        "  if x not in freq_dic:\n",
        "    x_freq = senseToValue(x, freq_df, 'freq', average=True, conservative=conservative)\n",
        "    if not np.isnan(x_freq):\n",
        "      freq_dic[x] = x_freq\n",
        "\n",
        "  if y not in freq_dic:\n",
        "    y_freq = senseToValue(y, freq_df, 'freq', average=True, conservative=conservative)\n",
        "    if not np.isnan(y_freq):\n",
        "      freq_dic[y] = y_freq\n",
        "\n",
        "  if x not in val_dic:\n",
        "    x_val = senseToValue(x, val_df, 'val', conservative=conservative)\n",
        "    if not np.isnan(x_val):\n",
        "      val_dic[x] = abs(x_val - 0.5)\n",
        "\n",
        "  if y not in val_dic:\n",
        "    y_val = senseToValue(y, val_df, 'val', conservative=conservative)\n",
        "    if not np.isnan(y_val):\n",
        "      val_dic[y] = abs(y_val - 0.5)"
      ],
      "metadata": {
        "id": "a3H1tDpjs-9a",
        "cellView": "code"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title export these as a dataframe, for use in other places\n",
        "\n",
        "# conc_sense_df = pd.DataFrame.from_dict(conc_dic, orient='index').reset_index().rename(columns={'index':'Word', 0:'conc'})\n",
        "# freq_sense_df = pd.DataFrame.from_dict(freq_dic, orient='index').reset_index().rename(columns={'index':'Word', 0:'freq'})\n",
        "# val_sense_df = pd.DataFrame.from_dict(val_dic, orient='index').reset_index().rename(columns={'index':'Word', 0:'val'})\n",
        "\n",
        "# df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning1',right_on='Word', how='left'), [sem_shift_df[['meaning1', 'meaning2']], conc_sense_df])\n",
        "# df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning2',right_on='Word', how='left'), [df, conc_sense_df])\n",
        "# df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning1',right_on='Word', how='left'), [df, freq_sense_df])\n",
        "# df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning2',right_on='Word', how='left'), [df, freq_sense_df])\n",
        "# df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning1',right_on='Word', how='left'), [df, val_sense_df])\n",
        "# df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning2',right_on='Word', how='left'), [df, val_sense_df])\n",
        "\n",
        "# df = df.drop(['Word_x', 'Word_y'], axis=1)\n",
        "\n",
        "# df.to_csv('all_vars_df.csv', index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1UejLcvLo1I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get group indices\n",
        "lang_df = sem_shift_df.groupby('language1').count().reset_index()\n",
        "lang_df = lang_df[lang_df['meaning1'] >=10]\n",
        "lang_list = lang_df['language1'].values\n",
        "sem_shift_df['language'] = sem_shift_df['language1'].map({y: x for x, y in dict(enumerate(lang_list)).items()})"
      ],
      "metadata": {
        "id": "8blSfTAF-GXn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up training and testing databases\n",
        "\n",
        "# get a dataframe with all the concreteness values and drop NaN\n",
        "conc_sense_df = pd.DataFrame.from_dict(conc_dic, orient='index').reset_index().rename(columns={'index':'Word', 0:'conc'})\n",
        "freq_sense_df = pd.DataFrame.from_dict(freq_dic, orient='index').reset_index().rename(columns={'index':'Word', 0:'freq'})\n",
        "val_sense_df = pd.DataFrame.from_dict(val_dic, orient='index').reset_index().rename(columns={'index':'Word', 0:'val'})\n",
        "shift_val_df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning1',right_on='Word', how='left'), [sem_shift_df, conc_sense_df]).drop('Word', axis=1)\n",
        "shift_val_df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning2',right_on='Word', how='left'), [shift_val_df, conc_sense_df]).drop('Word', axis=1)\n",
        "shift_val_df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning1',right_on='Word', how='left'), [shift_val_df, freq_sense_df]).drop('Word', axis=1)\n",
        "shift_val_df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning2',right_on='Word', how='left'), [shift_val_df, freq_sense_df]).drop('Word', axis=1)\n",
        "shift_val_df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning1',right_on='Word', how='left'), [shift_val_df, val_sense_df]).drop('Word', axis=1)\n",
        "shift_val_df = reduce(lambda  left,right: pd.merge(left,right,left_on='meaning2',right_on='Word', how='left'), [shift_val_df, val_sense_df]).drop('Word', axis=1)\n",
        "shift_val_df = shift_val_df.dropna().reset_index(drop=True)\n",
        "\n",
        "shift_val_df['conc_diff'] = shift_val_df['conc_y'] - shift_val_df['conc_x']\n",
        "shift_val_df['freq_diff'] = shift_val_df['freq_y'] - shift_val_df['freq_x']\n",
        "shift_val_df['val_diff'] = shift_val_df['val_y'] - shift_val_df['val_x']\n",
        "\n",
        "train_df = shift_val_df[['conc_diff', 'freq_diff', 'val_diff', 'language1']].copy() \n",
        "\n",
        "# create a train dataframe where half of the directions are switched \n",
        "indices = list(range(len(shift_val_df)))\n",
        "r.shuffle(indices)\n",
        "switch_indices = indices[:int(len(shift_val_df)/2)]\n",
        "\n",
        "train_df['accurate'] = pd.Series(dtype='int')\n",
        "train_df.loc[switch_indices, 'accurate'] = 0\n",
        "train_df.loc[indices[int(len(train_df)/2):], 'accurate'] = 1\n",
        "\n",
        "train_df.loc[switch_indices, 'conc_diff'] = -shift_val_df.loc[switch_indices, 'conc_diff']\n",
        "train_df.loc[switch_indices, 'freq_diff'] = -shift_val_df.loc[switch_indices, 'freq_diff']\n",
        "train_df.loc[switch_indices, 'val_diff'] = -shift_val_df.loc[switch_indices, 'val_diff']"
      ],
      "metadata": {
        "id": "O2mbGoUptRwR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do logistic regression as a baseline\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_df[['conc_diff', 'freq_diff', 'val_diff', 'language1']], train_df['accurate'].values, test_size=0.2, random_state=0)\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=0)\n",
        "model.fit(X_train[['conc_diff']].values, y_train)\n",
        "print(\"Concreteness:\", model.score(X_test[['conc_diff']].values, y_test))\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=0)\n",
        "model.fit(X_train[['freq_diff']].values, y_train)\n",
        "print(\"Frequency:\", model.score(X_test[['freq_diff']].values, y_test))\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=0)\n",
        "model.fit(X_train[['val_diff']].values, y_train)\n",
        "print(\"Valence:\", model.score(X_test[['val_diff']].values, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA68vjSYWyHn",
        "outputId": "e560c20a-ac61-44fb-a555-0875986e2aee"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concreteness: 0.7420718816067653\n",
            "Frequency: 0.4630021141649049\n",
            "Valence: 0.6680761099365751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GLMM\n",
        "\n",
        "# this is weird beacuse it's not really solving a classification problem? it's a linear fit problem. \n",
        "\n",
        "X_train['intercept'] = 1\n",
        "X_test['intercept'] = 1\n",
        "\n",
        "gp_model_conc = gpb.GPModel(group_data=X_train['language1'], likelihood='bernoulli_logit')  #either \"gaussian\" (=regression), \"bernoulli_probit\", \"bernoulli_logit\", (=classification)\"poisson\", or \"gamma\"\n",
        "gp_model_conc.fit(y=y_train, X=X_train[['conc_diff', 'intercept']], params={'std_dev': True})\n",
        "print(\"Concreteness\")\n",
        "print(gp_model_conc.summary())\n",
        "\n",
        "gp_model_freq = gpb.GPModel(group_data=X_train['language1'], likelihood='bernoulli_logit')  #either \"gaussian\" (=regression), \"bernoulli_probit\", \"bernoulli_logit\", (=classification)\"poisson\", or \"gamma\"\n",
        "gp_model_freq.fit(y=y_train, X=X_train[['freq_diff', 'intercept']], params={'std_dev': True})\n",
        "print(\"Freq\")\n",
        "print(gp_model_freq.summary())\n",
        "\n",
        "gp_model_val = gpb.GPModel(group_data=X_train['language1'], likelihood='bernoulli_logit')  #either \"gaussian\" (=regression), \"bernoulli_probit\", \"bernoulli_logit\", (=classification)\"poisson\", or \"gamma\"\n",
        "gp_model_val.fit(y=y_train, X=X_train[['val_diff', 'intercept']], params={'std_dev': True})\n",
        "print(\"Val\")\n",
        "print(gp_model_val.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t8RON-a5suu",
        "outputId": "fc2891dd-9561-4303-b64d-f49e8952726a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concreteness\n",
            "===================================================\n",
            "Model summary:\n",
            " Log-lik     AIC     BIC\n",
            " -978.33 1962.66 1979.29\n",
            "Nb. observations: 1889\n",
            "Nb. groups: 132 (language1)\n",
            "---------------------------------------------------\n",
            "Covariance parameters (random effects):\n",
            "           Param.\n",
            "language1  0.0123\n",
            "---------------------------------------------------\n",
            "Linear regression coefficients (fixed effects):\n",
            "           Param.  Std. dev.  z value  P(>|z|)\n",
            "conc_diff -1.3027     0.0664 -19.6239   0.0000\n",
            "intercept  0.0545     0.0571   0.9557   0.3392\n",
            "===================================================\n",
            "<gpboost.basic.GPModel object at 0x7fa9a93daf50>\n",
            "Freq\n",
            "===================================================\n",
            "Model summary:\n",
            " Log-lik     AIC     BIC\n",
            "-1298.36 2602.73 2619.36\n",
            "Nb. observations: 1889\n",
            "Nb. groups: 132 (language1)\n",
            "---------------------------------------------------\n",
            "Covariance parameters (random effects):\n",
            "           Param.\n",
            "language1  0.0034\n",
            "---------------------------------------------------\n",
            "Linear regression coefficients (fixed effects):\n",
            "           Param.  Std. dev.  z value  P(>|z|)\n",
            "freq_diff  0.0000     0.0000   4.4185   0.0000\n",
            "intercept -0.0049     0.0469  -0.1051   0.9163\n",
            "===================================================\n",
            "<gpboost.basic.GPModel object at 0x7fa9a93e3b10>\n",
            "Val\n",
            "===================================================\n",
            "Model summary:\n",
            " Log-lik     AIC     BIC\n",
            "-1156.21 2318.43 2335.06\n",
            "Nb. observations: 1889\n",
            "Nb. groups: 132 (language1)\n",
            "---------------------------------------------------\n",
            "Covariance parameters (random effects):\n",
            "           Param.\n",
            "language1  0.0119\n",
            "---------------------------------------------------\n",
            "Linear regression coefficients (fixed effects):\n",
            "           Param.  Std. dev.  z value  P(>|z|)\n",
            "val_diff   5.0822     0.3264  15.5721   0.0000\n",
            "intercept -0.0101     0.0519  -0.1951   0.8453\n",
            "===================================================\n",
            "<gpboost.basic.GPModel object at 0x7fa9ac04f650>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get accuracies for test \n",
        "\n",
        "pred = gp_model_conc.predict(X_pred=X_test[['conc_diff', 'intercept']], group_data_pred=X_test['language1'],\n",
        "                        predict_var=True, predict_response=False)\n",
        "accurate = [y_test[i] == (1 if pred['mu'][i]> 0 else 0) for i in range(len(y_test))]\n",
        "print('Conc accuracy', accurate.count(True)/len(accurate))\n",
        "\n",
        "pred = gp_model_freq.predict(X_pred=X_test[['freq_diff', 'intercept']], group_data_pred=X_test['language1'],\n",
        "                        predict_var=True, predict_response=False)\n",
        "accurate = [y_test[i] == (1 if pred['mu'][i]> 0 else 0) for i in range(len(y_test))]\n",
        "print('Freq accuracy', accurate.count(True)/len(accurate))\n",
        "\n",
        "pred = gp_model_val.predict(X_pred=X_test[['val_diff', 'intercept']], group_data_pred=X_test['language1'],\n",
        "                        predict_var=True, predict_response=False)\n",
        "accurate = [y_test[i] == (1 if pred['mu'][i]> 0 else 0) for i in range(len(y_test))]\n",
        "print('Val accuracy', accurate.count(True)/len(accurate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v67HV-ci67Xt",
        "outputId": "d1797e96-5d35-43fe-b187-2f6d0c963bbe"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conc accuracy 0.7441860465116279\n",
            "Freq accuracy 0.4714587737843552\n",
            "Val accuracy 0.6638477801268499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get coefficients for each language\n",
        "\n",
        "all_training_data_random_effects = gp_model_conc.predict_training_data_random_effects()\n",
        "first_occurences = [np.where(X_train['language1']==i)[0][0] for i in np.unique(X_train['language1'])]\n",
        "training_data_random_effects = all_training_data_random_effects.iloc[first_occurences].copy()\n",
        "training_data_random_effects['language'] = np.unique(X_train['language1'])"
      ],
      "metadata": {
        "id": "Jog48BWeF87r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_random_effects"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "SyLUVs17YT8f",
        "outputId": "4dceee58-7b66-4db9-d5b6-15b22bd039bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      language1       language\n",
              "462    0.024511          Abaza\n",
              "148    0.016003         Adyghe\n",
              "765    0.014948          Aghul\n",
              "76    -0.067963       Akkadian\n",
              "139    0.055759        Amharic\n",
              "...         ...            ...\n",
              "503    0.054471          Waray\n",
              "1089  -0.025446          Welsh\n",
              "37    -0.010031          Yakut\n",
              "56     0.005253  Yaqui (Hiaki)\n",
              "143   -0.012522           Zulu\n",
              "\n",
              "[132 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a632ef9a-0074-4e86-ac05-083b17baa319\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language1</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>0.024511</td>\n",
              "      <td>Abaza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.016003</td>\n",
              "      <td>Adyghe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>0.014948</td>\n",
              "      <td>Aghul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>-0.067963</td>\n",
              "      <td>Akkadian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>0.055759</td>\n",
              "      <td>Amharic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.054471</td>\n",
              "      <td>Waray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1089</th>\n",
              "      <td>-0.025446</td>\n",
              "      <td>Welsh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>-0.010031</td>\n",
              "      <td>Yakut</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.005253</td>\n",
              "      <td>Yaqui (Hiaki)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>-0.012522</td>\n",
              "      <td>Zulu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a632ef9a-0074-4e86-ac05-083b17baa319')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a632ef9a-0074-4e86-ac05-083b17baa319 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a632ef9a-0074-4e86-ac05-083b17baa319');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yMxMAy11YVCI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}